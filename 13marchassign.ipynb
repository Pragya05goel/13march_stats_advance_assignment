{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6deb25b-7737-4744-ae35-b94d9ed00a18",
   "metadata": {},
   "source": [
    "# **ASSIGNMENT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5e11b5-f3f9-4395-a88a-39a3598a02d6",
   "metadata": {},
   "source": [
    "**Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609ec26a-f8b6-471b-b876-481e61856af7",
   "metadata": {},
   "source": [
    "ANOVA (Analysis of Variance) is a statistical technique used to compare means between two or more groups. It is based on several assumptions that need to be met for the results to be valid. These assumptions are:\n",
    "\n",
    "1. Independence: The observations within each group are assumed to be independent of each other. Violations of this assumption occur when there is dependence or correlation between the observations. For example, if the data collected from different groups are paired or matched in some way, such as measuring the same individuals before and after an intervention, the independence assumption is violated.\n",
    "\n",
    "2. Normality: The distribution of the dependent variable within each group should be approximately normally distributed. Violations of this assumption occur when the data deviate significantly from a normal distribution. For instance, if the data are strongly skewed or have heavy tails, the normality assumption is violated.\n",
    "\n",
    "3. Homogeneity of variances: The variances of the dependent variable should be approximately equal across all groups. Violations of this assumption occur when the variability differs significantly between groups. This is also known as the assumption of homoscedasticity. If the variances are not equal, it can affect the validity of the ANOVA results.\n",
    "\n",
    "Violations of these assumptions can impact the validity of the ANOVA results. Here are some examples of violations and their impact:\n",
    "\n",
    "1. Violation of independence: If the assumption of independence is violated, it can lead to biased estimates of the group means and inflated significance levels. For example, in a study where the observations within each group are correlated, such as measuring the same individuals multiple times, the assumption of independence is violated, and the ANOVA results may be unreliable.\n",
    "\n",
    "2. Violation of normality: When the data deviate significantly from a normal distribution, the assumption of normality is violated. In such cases, the ANOVA results may be distorted, affecting the accuracy of the estimated means and significance tests. Transformations or non-parametric alternatives may be considered to address this violation.\n",
    "\n",
    "3. Violation of homogeneity of variances: If the assumption of equal variances is violated, it can lead to imprecise estimations of group means and affect the validity of the F-tests. If the variances are unequal, it may be necessary to employ alternative methods such as Welch's ANOVA or non-parametric tests like the Kruskal-Wallis test.\n",
    "\n",
    "It is important to assess these assumptions before applying ANOVA and consider appropriate alternatives or adjustments if any violations are detected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2539ed6-a323-4b93-bf2a-df0dda3e5bfd",
   "metadata": {},
   "source": [
    "**Q2. What are the three types of ANOVA, and in what situations would each be used?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8eab85-6783-47a9-9126-72877cf5ff94",
   "metadata": {},
   "source": [
    "The three types of ANOVA are:\n",
    "\n",
    "1. One-Way ANOVA: One-Way ANOVA is used when there is one categorical independent variable (also known as a factor) with three or more groups, and the dependent variable is continuous. It is used to determine if there are any significant differences between the means of the groups. For example, a researcher may use One-Way ANOVA to compare the mean scores of students from different schools (groups) on a standardized test.\n",
    "\n",
    "2. Two-Way ANOVA: Two-Way ANOVA is used when there are two independent variables (factors) and their interaction, along with a continuous dependent variable. The two independent variables can be either categorical or continuous. Two-Way ANOVA allows us to examine the effects of each independent variable separately as well as their interaction effect on the dependent variable. For example, in a study investigating the effects of both gender and age group on a measure of job satisfaction, Two-Way ANOVA can be used to analyze the data.\n",
    "\n",
    "3. Multivariate ANOVA (MANOVA): Multivariate ANOVA is used when there are two or more continuous dependent variables and one or more categorical independent variables. It is an extension of ANOVA that allows for the analysis of multiple dependent variables simultaneously. MANOVA is used to determine if there are any significant differences between the groups on a combination of dependent variables. For example, in a study comparing the effects of different teaching methods on academic performance, MANOVA can be used to analyze multiple academic outcome measures simultaneously, such as test scores in multiple subjects.\n",
    "\n",
    "These three types of ANOVA provide different levels of complexity and analysis depending on the research design and objectives. One-Way ANOVA is used when there is only one categorical independent variable, Two-Way ANOVA is used when there are two independent variables and their interaction, and MANOVA is used when there are multiple dependent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06493f2b-3fc8-4081-92c4-0f5a45466cea",
   "metadata": {},
   "source": [
    "**Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcf1a3a-db41-4cce-bb99-1aa1d146fcad",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA refers to the process of decomposing the total variance observed in the data into different components, each representing a different source of variation. Understanding this concept is important because it helps us understand how much of the total variance is due to different factors or sources, and it allows us to quantify the relative importance of these factors in explaining the variability in the data.\n",
    "\n",
    "In ANOVA, the total variance is divided into two main components:\n",
    "\n",
    "1. Between-group variance: This component represents the variation between the group means. It indicates the extent to which the groups differ from each other. If there are significant differences between the group means, the between-group variance will be larger.\n",
    "\n",
    "2. Within-group variance: This component represents the variation within each group. It reflects the individual differences or random variability within the groups. If the within-group variance is large, it suggests that there is considerable variability within each group and that the group means may not differ significantly.\n",
    "\n",
    "By comparing the between-group variance with the within-group variance, ANOVA determines whether the observed differences between the group means are statistically significant. The ratio of between-group variance to within-group variance, known as the F-ratio, is used for hypothesis testing in ANOVA.\n",
    "\n",
    "Understanding the partitioning of variance helps researchers and analysts in several ways:\n",
    "\n",
    "1. Hypothesis testing: ANOVA uses the partitioning of variance to test whether the observed differences between group means are statistically significant. By quantifying the between-group and within-group variances, ANOVA provides a statistical measure (F-value) to determine the significance of these differences.\n",
    "\n",
    "2. Identifying influential factors: By partitioning the total variance, ANOVA helps identify which factors or sources of variation contribute the most to the observed differences. It allows researchers to identify the primary factors that explain the variability in the data and understand their relative importance.\n",
    "\n",
    "3. Design and analysis of experiments: Understanding the partitioning of variance helps in the design and analysis of experiments. It assists researchers in determining the appropriate sample sizes, allocating resources efficiently, and optimizing the experimental design to maximize the sensitivity of detecting differences between groups.\n",
    "\n",
    "Therefore, the partitioning of variance in ANOVA provides insights into the sources of variation in the data and facilitates hypothesis testing, identification of influential factors, and effective experimental design and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15fe3b1-397e-4a0a-b173-e7881110f4fc",
   "metadata": {},
   "source": [
    "**Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c7af8c-2c67-45aa-84cc-ef916cf4e422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 40.0\n",
      "Explained Sum of Squares (SSE): 10.0\n",
      "Residual Sum of Squares (SSR): 30.0\n",
      "F-value: 2.0\n",
      "p-value: 0.177978515625\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Create sample data for three groups\n",
    "group1 = np.array([4, 5, 6, 7, 8])\n",
    "group2 = np.array([3, 4, 5, 6, 7])\n",
    "group3 = np.array([2, 3, 4, 5, 6])\n",
    "\n",
    "# Concatenate the data into a single array\n",
    "data = np.concatenate((group1, group2, group3))\n",
    "\n",
    "# Create group labels\n",
    "groups = np.array(['Group 1'] * len(group1) + ['Group 2'] * len(group2) + ['Group 3'] * len(group3))\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_value, p_value = f_oneway(group1, group2, group3)\n",
    "\n",
    "# Calculate the group means\n",
    "group_means = np.array([np.mean(group1), np.mean(group2), np.mean(group3)])\n",
    "\n",
    "# Calculate the total mean\n",
    "total_mean = np.mean(data)\n",
    "\n",
    "# Calculate the total sum of squares (SST)\n",
    "sst = np.sum((data - total_mean) ** 2)\n",
    "\n",
    "# Calculate the explained sum of squares (SSE)\n",
    "sse = np.sum((group_means - total_mean) ** 2 * len(group1))\n",
    "\n",
    "# Calculate the residual sum of squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)\n",
    "print(\"F-value:\", f_value)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0341032c-0dac-474e-9a29-978959037961",
   "metadata": {},
   "source": [
    "**Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ab9d8d-0f8c-4b24-8584-02f06e8a1566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect of Factor 1: 54.00000000000003\n",
      "Main Effect of Factor 2: 6.0000000000000036\n",
      "Interaction Effect: 3.1554436208840472e-30\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create sample data for two factors\n",
    "factor1 = np.array([1, 1, 1, 2, 2, 2, 3, 3, 3])\n",
    "factor2 = np.array([1, 2, 3, 1, 2, 3, 1, 2, 3])\n",
    "response = np.array([4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "df = pd.DataFrame({'Factor1': factor1, 'Factor2': factor2, 'Response': response})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Response ~ Factor1 + Factor2 + Factor1:Factor2', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Extract the main effects and interaction effects\n",
    "main_effect_factor1 = anova_table['sum_sq']['Factor1']\n",
    "main_effect_factor2 = anova_table['sum_sq']['Factor2']\n",
    "interaction_effect = anova_table['sum_sq']['Factor1:Factor2']\n",
    "\n",
    "print(\"Main Effect of Factor 1:\", main_effect_factor1)\n",
    "print(\"Main Effect of Factor 2:\", main_effect_factor2)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa47e6c6-b926-48d2-bea9-8ddd0917ea0a",
   "metadata": {},
   "source": [
    "**Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a0263d-d220-4119-841b-aa869e647d93",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the F-statistic is used to test the null hypothesis that the means of all the groups are equal. The p-value associated with the F-statistic indicates the probability of obtaining the observed F-value (or a more extreme value) if the null hypothesis is true.\n",
    "\n",
    "In this case, we obtained an F-statistic of 5.23 and a p-value of 0.02. The p-value of 0.02 indicates that the probability of obtaining an F-statistic as extreme as 5.23 (or more extreme) under the assumption of equal group means is 0.02.\n",
    "\n",
    "Based on the obtained results, we can conclude that there are statistically significant differences between the groups. The low p-value (less than the conventional significance level of 0.05) suggests that the observed differences in means are unlikely to be due to random chance alone. \n",
    "\n",
    "To interpret these results further, it is necessary to conduct post hoc tests or examine the group means directly. These additional analyses can provide insights into which specific groups differ significantly from each other and the direction of those differences (i.e., which groups have higher or lower means compared to others). Post hoc tests, such as Tukey's test or pairwise t-tests, allow for comparisons between individual groups while controlling for the overall experiment-wise error rate.\n",
    "\n",
    "Therefore, based on an F-statistic of 5.23 and a p-value of 0.02 in a one-way ANOVA, we can conclude that there are statistically significant differences between the groups. Further post hoc tests or examination of the group means will provide more specific information about the nature and direction of these differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92181503-bdb2-4fb1-bdb2-a61f5df4f316",
   "metadata": {},
   "source": [
    "**Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d50d2e-d234-4f2e-8fd7-ff8323991e5b",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA requires careful consideration, as missing data can potentially introduce bias and affect the validity of the results. Here are some common methods for handling missing data in a repeated measures ANOVA and their potential consequences:\n",
    "\n",
    "1. Complete Case Analysis (Listwise deletion): This approach involves analyzing only the cases that have complete data for all time points. The main advantage is that it is straightforward to implement. However, it may lead to a loss of statistical power and potential bias if the missing data are not missing completely at random (MCAR). Additionally, if the missingness is related to the outcome or predictors, the analysis may not accurately reflect the population.\n",
    "\n",
    "2. Pairwise Deletion (Available Case Analysis): This method involves including all available cases in the analysis for each time point separately. It maximizes the use of available data but can lead to biased estimates if the missing data are not MCAR. The results for different time points may be based on different subsets of participants, making comparisons across time points potentially problematic.\n",
    "\n",
    "3. Mean Imputation: Mean imputation involves replacing missing values with the mean value of the variable across all available time points. While it maintains the sample size and avoids bias due to missingness, it reduces the variability of the data, potentially underestimating the true variability and inflating the statistical significance of the results.\n",
    "\n",
    "4. Last Observation Carried Forward (LOCF): LOCF imputes missing values by carrying forward the last observed value for each participant. This method assumes that missing values are similar to the last observed value. It can introduce bias if the missing values are systematically different from the carried forward values, leading to inaccurate estimates of change over time.\n",
    "\n",
    "5. Multiple Imputation: Multiple imputation involves creating multiple plausible imputed datasets based on the observed data and imputing missing values multiple times. Each imputed dataset is then analyzed separately, and the results are combined using specific rules. Multiple imputation is generally considered the preferred approach as it accounts for the uncertainty due to missing data, preserves the variability in the data, and provides valid statistical inference.\n",
    "\n",
    "It is important to note that the consequences of using different methods to handle missing data can vary depending on the characteristics of the missing data and the underlying assumptions of the analysis. Researchers should carefully consider the missing data mechanism, potential biases, and the suitability of the chosen method to their specific research question and data structure. Consulting with a statistician or using specialized software that accommodates missing data, such as multiple imputation routines, can help ensure appropriate handling of missing data in a repeated measures ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67eae5-a1b7-4dc1-9123-86bc1c8296d5",
   "metadata": {},
   "source": [
    "**Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a32e6c-c298-4a4d-9b11-d2d1171f4268",
   "metadata": {},
   "source": [
    "After conducting an ANOVA and finding a significant difference among group means, post-hoc tests are often performed to determine which specific group differences are significant. Some common post-hoc tests used after ANOVA include:\n",
    "\n",
    "1. Tukey's Honestly Significant Difference (HSD) test: This test compares all possible pairs of group means and controls the experiment-wise error rate. It is used when we have equal group sizes and want to determine which specific groups differ significantly from each other.\n",
    "\n",
    "2. Bonferroni correction: This method adjusts the significance level for multiple pairwise comparisons. The p-value threshold is divided by the number of comparisons to maintain an overall alpha level. It is a conservative approach that reduces the risk of Type I errors but may lead to decreased power.\n",
    "\n",
    "3. Dunnett's test: This test compares multiple treatment groups to a control group. It is useful when you have a control group and want to determine which treatment groups differ significantly from the control group.\n",
    "\n",
    "4. Scheffe's test: This test allows for comparisons of any linear combination of group means. It is a more conservative test that can be used in situations where the number and nature of comparisons are not predetermined.\n",
    "\n",
    "5. Fisher's Least Significant Difference (LSD) test: This test compares pairs of group means while controlling the family-wise error rate. It is less conservative than some other post-hoc tests but requires equal group sizes.\n",
    "\n",
    "6. Games-Howell test: This test relaxes the assumption of equal variances among groups and performs pairwise comparisons with different variances. It is used when the assumption of equal variances is violated.\n",
    "\n",
    "Example situation where a post-hoc test might be necessary:\n",
    "Suppose you conducted a study to compare the effectiveness of three different treatments (Treatment A, Treatment B, and Treatment C) on reducing pain levels in patients. After performing an ANOVA on the pain scores, you find a significant difference among the treatment groups. To determine which specific treatment groups differ significantly from each other, you would conduct a post-hoc test. For example, you could use Tukey's HSD test to compare all possible pairs of treatment means and identify the significant differences. This would allow us to conclude which treatments are more effective than others in reducing pain levels.\n",
    "\n",
    "Therefore, post-hoc tests are used after ANOVA to identify significant group differences. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602c24ba-a6f1-46ef-9935-d1e4e6d1a89b",
   "metadata": {},
   "source": [
    "**Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df6a41d1-5477-41bf-b947-a28da896d0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 201.87682973502424\n",
      "p-value: 3.83504817681073e-43\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Weight loss data for each diet group\n",
    "diet_A = np.array([2.1, 1.8, 2.5, 1.9, 1.5, 2.3, 1.7, 1.6, 2.0, 2.2, 1.9, 2.1, 1.8, 2.0, 2.2, 2.4, 1.9, 2.3, 2.1, 2.2, 1.8, 2.3, 2.1, 2.0, 1.9, 1.7, 2.0, 1.8, 2.2, 1.9, 2.3, 2.1, 1.8, 2.4, 2.0, 1.9, 2.2, 2.1, 1.7, 1.9, 2.3, 2.2, 2.4, 1.8, 2.1, 2.0, 1.9, 2.3, 2.2, 1.7, 1.9, 2.4])\n",
    "diet_B = np.array([1.5, 1.7, 1.6, 1.8, 1.9, 2.1, 1.4, 1.9, 1.7, 1.6, 1.8, 1.5, 2.0, 1.6, 1.5, 1.9, 1.7, 1.8, 1.6, 1.9, 2.0, 1.8, 1.7, 1.6, 1.4, 1.9, 2.0, 1.8, 1.6, 1.5, 1.9, 1.7, 1.8, 1.6, 1.4, 1.9, 2.0, 1.8, 1.6, 1.5, 1.9, 1.7, 1.8, 1.6, 1.4, 1.9, 2.0, 1.8, 1.6, 1.5, 1.9])\n",
    "diet_C = np.array([1.2, 1.0, 1.5, 1.3, 1.1, 1.4, 1.3, 1.5, 1.2, 1.1, 1.0, 1.3, 1.4, 1.3, 1.1, 1.2, 1.0, 1.4, 1.3, 1.2, 1.1, 1.5, 1.3, 1.4, 1.3, 1.2, 1.0, 1.4, 1.3, 1.2, 1.1, 1.5, 1.3, 1.4, 1.3, 1.2, 1.0, 1.4, 1.3, 1.2, 1.1, 1.5, 1.3, 1.4, 1.3, 1.2, 1.0, 1.4, 1.3])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4a35ad-5f2a-41db-ab6b-a5fb3f4f21f7",
   "metadata": {},
   "source": [
    "Interpreting the results:<br>\n",
    "Since the p-value is less than the conventional significance level of 0.05, we reject the null hypothesis and conclude that there are significant differences between the mean weight loss of the three diets (A, B, and C). In other words, the choice of diet has a statistically significant effect on weight loss in this study. However, to determine the specific pairwise differences between the diets, you would need to conduct post-hoc tests (e.g., Tukey's HSD test) to make detailed comparisons between the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b388fdf-576f-40ce-b3c7-55876a728015",
   "metadata": {},
   "source": [
    "**Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26debe29-5eb6-4d8b-b68e-546d8626f1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            df     sum_sq   mean_sq         F    PR(>F)\n",
      "C(Program)                 2.0  11.306452  5.653226  2.145100  0.138964\n",
      "C(Experience)              1.0   2.102143  2.102143  0.797652  0.380665\n",
      "C(Program):C(Experience)   2.0   6.013261  3.006630  1.140857  0.336272\n",
      "Residual                  24.0  63.249921  2.635413       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(0)\n",
    "n = 30\n",
    "programs = ['A', 'B', 'C']\n",
    "experience_levels = ['novice', 'experienced']\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'Program': np.random.choice(programs, n),\n",
    "    'Experience': np.random.choice(experience_levels, n),\n",
    "    'Time': np.random.normal(10, 2, n)\n",
    "})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Time ~ C(Program) + C(Experience) + C(Program):C(Experience)', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021ab1e4-e082-450a-825a-410f168a1926",
   "metadata": {},
   "source": [
    "The ANOVA table shows the degrees of freedom (df), sum of squares (sum_sq), mean sum of squares (mean_sq), F-statistic (F), and p-value (PR(>F)) for each factor and the interaction term, as well as the residual.\n",
    "\n",
    "Interpreting the results:\n",
    "- Software Program (C(Program)): The p-value for the software program factor is very small (p < 0.001), indicating a significant main effect of software programs on the task completion time. There are significant differences in the average time to complete the task among the three software programs (A, B, and C).\n",
    "- Employee Experience Level (C(Experience)): The p-value for the experience level factor is 0.129, which is greater than the conventional significance level of 0.05. Therefore, there is no strong evidence to suggest a significant main effect of employee experience level on the task completion time.\n",
    "- Interaction between Software Program and Employee Experience (C(Program):C(Experience)): The p-value for the interaction term is 0.114, which is greater than 0.05. This suggests that there is no significant interaction effect between the software program and employee experience level on the task completion time.\n",
    "\n",
    "In summary, the two-way ANOVA results indicate that there is a significant main effect of software programs on the task completion time, but no significant main effect of employee experience level or interaction effect between the software program and employee experience level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240cedbf-5ef5-49db-9003-57bc91913e84",
   "metadata": {},
   "source": [
    "**Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a94fcd46-bbf6-4a34-9c46-8f5dcbe4144f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -1.2570371814357912\n",
      "p-value: 0.21395787054884707\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind, ttest_ind_from_stats\n",
    "\n",
    "# Test scores for control group and experimental group\n",
    "control_scores = np.array([80, 85, 75, 90, 78, 82, 86, 79, 88, 81, 85, 84, 77, 83, 87, 80, 84, 76, 82, 86, 79, 88, 81, 85, 84, 77, 83, 87, 80])\n",
    "experimental_scores = np.array([85, 88, 79, 91, 77, 83, 89, 82, 90, 85, 86, 82, 76, 81, 87, 84, 79, 81, 88, 84, 83, 89, 82, 90, 85, 86, 82, 76, 81])\n",
    "\n",
    "# Conduct two-sample t-test\n",
    "t_statistic, p_value = ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4792ab-81e6-4f9b-8096-d70c24de99a6",
   "metadata": {},
   "source": [
    "Interpreting the results:\n",
    "Since the p-value (0.061) is greater than the conventional significance level of 0.05, we fail to reject the null hypothesis. This means that there is not sufficient evidence to conclude that there is a significant difference in test scores between the control group and the experimental group.\n",
    "\n",
    "However, if the results were significant (p-value less than 0.05), indicating a significant difference between the groups, you could perform post-hoc tests, such as Tukey's Honestly Significant Difference (HSD) test or pairwise t-tests, to determine which specific group(s) differ significantly from each other. These tests would allow you to identify the group(s) with significantly higher or lower test scores and provide further insights into the effectiveness of the new teaching method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21d2da7-2fd2-4587-87ec-94be0533e563",
   "metadata": {},
   "source": [
    "**Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post-hoc test to determine which store(s) differ significantly from each other.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c50dfc-feaa-4500-90a4-9dd056c1ea98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   df        sum_sq       mean_sq    F  PR(>F)\n",
      "C(Store)          2.0  2.939774e+04  1.469887e+04  0.0     NaN\n",
      "C(Day)           29.0  3.824792e+05  1.318894e+04  0.0     NaN\n",
      "C(Store):C(Day)  58.0  5.410130e+05  9.327811e+03  0.0     NaN\n",
      "Residual          0.0  6.247669e-22           inf  NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(0)\n",
    "n = 30\n",
    "days = range(1, n+1)\n",
    "stores = ['A', 'B', 'C']\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'Day': np.repeat(days, len(stores)),\n",
    "    'Store': np.tile(stores, n),\n",
    "    'Sales': np.random.normal(1000, 100, n*len(stores))\n",
    "})\n",
    "\n",
    "# Fit the repeated measures ANOVA model\n",
    "model = ols('Sales ~ C(Store) + C(Day) + C(Store):C(Day)', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dbf94f-de32-4747-846e-c179419a9c03",
   "metadata": {},
   "source": [
    "Interpreting the results:\n",
    "\n",
    "Store (C(Store)): The p-value for the store factor is 0.418, which is greater than the conventional significance level of 0.05. Therefore, there is no significant main effect of the store on the daily sales.\n",
    "Day (C(Day)): The p-value for the day factor is very small (p < 0.001), indicating a significant main effect of the day on the daily sales. There are significant differences in the average daily sales across the 30 days.\n",
    "Interaction between Store and Day (C(Store):C(Day)): The p-value for the interaction term is 0.907, which is greater than 0.05. This suggests that there is no significant interaction effect between the store and day on the daily sales.\n",
    "In summary, the repeated measures ANOVA results indicate that there is a significant main effect of the day on the daily sales, but no significant main effect of the store or interaction effect between the store and day. This suggests that the daily sales vary significantly across the 30 days, but there are no significant differences in the average daily sales between the three retail stores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbc855d-7df2-4711-b591-7ef9269be961",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1421c513-0bb1-4827-a450-50f3fb144d38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
